# AMOSKYS Repository Reorganization Plan

**Based on**: Data Flow Analysis of 1,403 real events
**Date**: October 28, 2025
**Goal**: Organize repository to mirror actual data flow and improve developer experience

---

## Current State Assessment

### Existing Structure

```
Amoskys/
â”œâ”€â”€ amoskys-eventbus              # Executable
â”œâ”€â”€ amoskys-snmp-agent            # Executable
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ wal/
â”‚   â”‚   â”œâ”€â”€ flowagent.db          # 1,403 events, 227 KB
â”‚   â”‚   â””â”€â”€ sample_events.json    # Exported samples
â”‚   â””â”€â”€ ml_pipeline/              # ML outputs
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ proto/                        # Protobuf schemas
â”œâ”€â”€ scripts/                      # Utility scripts
â”œâ”€â”€ src/amoskys/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ snmp/
â”‚   â”œâ”€â”€ eventbus/
â”‚   â”œâ”€â”€ proto/
â”‚   â””â”€â”€ web/
â”œâ”€â”€ tests/                        # Test files
â””â”€â”€ web/                          # Flask dashboard
```

### Issues with Current Structure

1. âŒ **Mixed concerns**: Proto files in both `/proto` and `/src/amoskys/proto`
2. âŒ **Unclear data flow**: Hard to understand pipeline from directory structure
3. âŒ **Scripts scattered**: Analysis tools mixed with ML scripts mixed with utilities
4. âŒ **No clear separation**: Collection â†’ Ingestion â†’ Processing â†’ Intelligence â†’ Presentation
5. âŒ **Duplicate web folders**: `/web` and `/src/amoskys/web`

---

## Proposed Structure (Data Flow Aligned)

### Principle: **Directory Structure Mirrors Data Pipeline**

```
Amoskys/
â”‚
â”œâ”€â”€ ğŸ“‹ DOCUMENTATION/
â”‚   â”œâ”€â”€ README.md                              # Main project overview
â”‚   â”œâ”€â”€ ARCHITECTURE.md                        # System architecture
â”‚   â”œâ”€â”€ DATA_FLOW_ANALYSIS.md                  # âœ… Critical findings doc
â”‚   â”œâ”€â”€ PIPELINE_STATUS_REPORT.md              # Operational status
â”‚   â”œâ”€â”€ REPOSITORY_REORGANIZATION.md           # This file
â”‚   â”œâ”€â”€ QUICK_START.md                         # Getting started guide
â”‚   â””â”€â”€ API_REFERENCE.md                       # API documentation
â”‚
â”œâ”€â”€ ğŸ”§ CONFIGURATION/
â”‚   â”œâ”€â”€ config.yaml                            # Main configuration
â”‚   â”œâ”€â”€ snmp_oids.yaml                         # SNMP metric definitions
â”‚   â”œâ”€â”€ ml_models_config.yaml                  # ML model parameters
â”‚   â””â”€â”€ deployment/
â”‚       â”œâ”€â”€ docker-compose.yml
â”‚       â”œâ”€â”€ kubernetes/
â”‚       â””â”€â”€ systemd/
â”‚
â”œâ”€â”€ ğŸ“Š SCHEMAS/
â”‚   â”œâ”€â”€ proto/                                 # Protobuf definitions
â”‚   â”‚   â”œâ”€â”€ messaging_schema.proto             # Legacy FlowEvent schema
â”‚   â”‚   â””â”€â”€ universal_telemetry.proto          # New telemetry schema
â”‚   â””â”€â”€ sql/
â”‚       â”œâ”€â”€ wal_schema.sql                     # WAL database schema
â”‚       â””â”€â”€ telemetry_schema.sql               # Future: Rich telemetry DB
â”‚
â”œâ”€â”€ ğŸ¯ PIPELINE STAGE 1: DATA COLLECTION/
â”‚   â”œâ”€â”€ src/amoskys/collectors/                # Renamed from 'agents'
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_collector.py                  # Abstract base class
â”‚   â”‚   â”œâ”€â”€ snmp/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ snmp_collector.py              # Main SNMP logic
â”‚   â”‚   â”‚   â”œâ”€â”€ oid_definitions.py             # OID mappings
â”‚   â”‚   â”‚   â””â”€â”€ device_profiles.py             # Device-specific configs
â”‚   â”‚   â”œâ”€â”€ mqtt/
â”‚   â”‚   â”‚   â””â”€â”€ mqtt_collector.py
â”‚   â”‚   â”œâ”€â”€ pcap/
â”‚   â”‚   â”‚   â””â”€â”€ packet_collector.py
â”‚   â”‚   â””â”€â”€ process/
â”‚   â”‚       â””â”€â”€ process_collector.py
â”‚   â”œâ”€â”€ bin/                                   # Executables
â”‚   â”‚   â”œâ”€â”€ amoskys-snmp-collector             # Renamed from amoskys-snmp-agent
â”‚   â”‚   â”œâ”€â”€ amoskys-mqtt-collector
â”‚   â”‚   â””â”€â”€ amoskys-pcap-collector
â”‚   â””â”€â”€ tests/collectors/
â”‚       â””â”€â”€ test_snmp_collector.py
â”‚
â”œâ”€â”€ ğŸš€ PIPELINE STAGE 2: DATA INGESTION/
â”‚   â”œâ”€â”€ src/amoskys/ingestion/                 # EventBus + WAL
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ eventbus/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ server.py                      # gRPC EventBus server
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py                      # EventBus client
â”‚   â”‚   â”‚   â””â”€â”€ deduplication.py               # Idempotency logic
â”‚   â”‚   â”œâ”€â”€ wal/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ storage.py                     # WAL write operations
â”‚   â”‚   â”‚   â”œâ”€â”€ reader.py                      # WAL read operations
â”‚   â”‚   â”‚   â””â”€â”€ compaction.py                  # WAL maintenance
â”‚   â”‚   â””â”€â”€ validation/
â”‚   â”‚       â”œâ”€â”€ signature_validator.py         # Ed25519 verification
â”‚   â”‚       â””â”€â”€ schema_validator.py            # Protobuf validation
â”‚   â”œâ”€â”€ bin/
â”‚   â”‚   â””â”€â”€ amoskys-eventbus                   # EventBus executable
â”‚   â””â”€â”€ tests/ingestion/
â”‚       â”œâ”€â”€ test_eventbus.py
â”‚       â””â”€â”€ test_wal.py
â”‚
â”œâ”€â”€ ğŸ”„ PIPELINE STAGE 3: DATA TRANSFORMATION (ETL)/
â”‚   â”œâ”€â”€ src/amoskys/transformation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ wal_extractor.py               # Extract from WAL
â”‚   â”‚   â”‚   â””â”€â”€ protobuf_parser.py             # Parse protobuf events
â”‚   â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ canonical_features.py          # Stage 1: Base features
â”‚   â”‚   â”‚   â”œâ”€â”€ temporal_features.py           # Stage 2: Time-based
â”‚   â”‚   â”‚   â”œâ”€â”€ cross_features.py              # Stage 3: Correlations
â”‚   â”‚   â”‚   â”œâ”€â”€ domain_features.py             # Stage 4: Domain-specific
â”‚   â”‚   â”‚   â””â”€â”€ anomaly_features.py            # Stage 5: Outlier detection
â”‚   â”‚   â”œâ”€â”€ loading/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ parquet_writer.py              # Export to Parquet
â”‚   â”‚   â”‚   â”œâ”€â”€ csv_writer.py                  # Export to CSV
â”‚   â”‚   â”‚   â””â”€â”€ feature_store.py               # Feature database
â”‚   â”‚   â””â”€â”€ pipeline.py                        # Orchestrates full ETL
â”‚   â”œâ”€â”€ scripts/etl/                           # ETL execution scripts
â”‚   â”‚   â”œâ”€â”€ run_full_pipeline.py               # Main pipeline runner
â”‚   â”‚   â”œâ”€â”€ run_incremental.py                 # Process new data only
â”‚   â”‚   â””â”€â”€ backfill_features.py               # Historical reprocessing
â”‚   â””â”€â”€ tests/transformation/
â”‚       â””â”€â”€ test_feature_engineering.py
â”‚
â”œâ”€â”€ ğŸ§  PIPELINE STAGE 4: INTELLIGENCE (ML)/
â”‚   â”œâ”€â”€ src/amoskys/intelligence/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ isolation_forest.py            # Anomaly detection
â”‚   â”‚   â”‚   â”œâ”€â”€ xgboost_classifier.py          # Supervised learning
â”‚   â”‚   â”‚   â”œâ”€â”€ lstm_autoencoder.py            # Temporal patterns
â”‚   â”‚   â”‚   â””â”€â”€ ensemble.py                    # Multi-model fusion
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer.py                     # Model training orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuning.py       # AutoML
â”‚   â”‚   â”‚   â””â”€â”€ validation.py                  # Cross-validation
â”‚   â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ realtime_scorer.py             # Live threat scoring
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_predictor.py             # Batch processing
â”‚   â”‚   â”‚   â””â”€â”€ model_loader.py                # Model management
â”‚   â”‚   â””â”€â”€ fusion/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ score_junction.py              # Multi-model aggregation
â”‚   â”‚       â””â”€â”€ threat_ranker.py               # Priority scoring
â”‚   â”œâ”€â”€ notebooks/                             # Research & experimentation
â”‚   â”‚   â”œâ”€â”€ exploratory_data_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ feature_engineering_research.ipynb
â”‚   â”‚   â”œâ”€â”€ model_training.ipynb
â”‚   â”‚   â””â”€â”€ evaluation_metrics.ipynb
â”‚   â”œâ”€â”€ scripts/ml/
â”‚   â”‚   â”œâ”€â”€ train_all_models.py
â”‚   â”‚   â”œâ”€â”€ evaluate_models.py
â”‚   â”‚   â””â”€â”€ deploy_models.py
â”‚   â””â”€â”€ tests/intelligence/
â”‚       â”œâ”€â”€ test_models.py
â”‚       â””â”€â”€ test_inference.py
â”‚
â”œâ”€â”€ ğŸ¨ PIPELINE STAGE 5: PRESENTATION/
â”‚   â”œâ”€â”€ src/amoskys/presentation/              # User interfaces
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ app.py                         # Flask application
â”‚   â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events_api.py              # Event endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_api.py             # Metrics endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ threats_api.py             # Threat endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ devices_api.py             # Device endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ templates/                     # HTML templates
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.html
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ threats.html
â”‚   â”‚   â”‚   â””â”€â”€ static/                        # CSS, JS, images
â”‚   â”‚   â”‚       â”œâ”€â”€ css/
â”‚   â”‚   â”‚       â”œâ”€â”€ js/
â”‚   â”‚   â”‚       â””â”€â”€ img/
â”‚   â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ amoskys_cli.py                 # Command-line interface
â”‚   â”‚   â””â”€â”€ alerts/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ email_alerter.py
â”‚   â”‚       â”œâ”€â”€ slack_alerter.py
â”‚   â”‚       â””â”€â”€ pagerduty_alerter.py
â”‚   â”œâ”€â”€ bin/
â”‚   â”‚   â”œâ”€â”€ amoskys-dashboard                  # Dashboard server
â”‚   â”‚   â””â”€â”€ amoskys                            # CLI tool
â”‚   â””â”€â”€ tests/presentation/
â”‚       â””â”€â”€ test_dashboard_api.py
â”‚
â”œâ”€â”€ ğŸ“¦ DATA/                                   # All data artifacts
â”‚   â”œâ”€â”€ wal/                                   # Write-Ahead Log database
â”‚   â”‚   â”œâ”€â”€ flowagent.db                       # 1,403 events
â”‚   â”‚   â””â”€â”€ sample_events.json                 # Exported samples
â”‚   â”œâ”€â”€ features/                              # Processed features
â”‚   â”‚   â”œâ”€â”€ canonical_telemetry.parquet
â”‚   â”‚   â”œâ”€â”€ train_features.parquet
â”‚   â”‚   â”œâ”€â”€ val_features.parquet
â”‚   â”‚   â””â”€â”€ feature_metadata.json
â”‚   â”œâ”€â”€ models/                                # Trained ML models
â”‚   â”‚   â”œâ”€â”€ isolation_forest_v1.pkl
â”‚   â”‚   â”œâ”€â”€ xgboost_v1.pkl
â”‚   â”‚   â””â”€â”€ ensemble_v1.pkl
â”‚   â”œâ”€â”€ checkpoints/                           # Training checkpoints
â”‚   â””â”€â”€ exports/                               # Data exports for analysis
â”‚
â”œâ”€â”€ ğŸ” ANALYSIS TOOLS/                         # Data inspection & debugging
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ inspect_wal_events.py              # âœ… Inspect WAL database
â”‚   â”‚   â”œâ”€â”€ visualize_timeline.py              # âœ… Timeline visualization
â”‚   â”‚   â”œâ”€â”€ analyze_telemetry_pipeline.py      # âœ… Pipeline health check
â”‚   â”‚   â”œâ”€â”€ verify_signatures.py               # Cryptographic validation
â”‚   â”‚   â”œâ”€â”€ benchmark_performance.py           # Performance testing
â”‚   â”‚   â””â”€â”€ generate_reports.py                # Status reporting
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ data_explorer.py                   # Interactive data browser
â”‚       â””â”€â”€ metric_simulator.py                # Generate test data
â”‚
â”œâ”€â”€ ğŸ§ª TESTING/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ unit/                              # Unit tests
â”‚   â”‚   â”œâ”€â”€ integration/                       # Integration tests
â”‚   â”‚   â”œâ”€â”€ performance/                       # Load & stress tests
â”‚   â”‚   â””â”€â”€ fixtures/                          # Test data
â”‚   â”œâ”€â”€ pytest.ini
â”‚   â”œâ”€â”€ conftest.py
â”‚   â””â”€â”€ coverage.xml
â”‚
â”œâ”€â”€ ğŸš¢ DEPLOYMENT/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.collector
â”‚   â”‚   â”œâ”€â”€ Dockerfile.eventbus
â”‚   â”‚   â”œâ”€â”€ Dockerfile.dashboard
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”œâ”€â”€ collector-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ eventbus-deployment.yaml
â”‚   â”‚   â””â”€â”€ dashboard-deployment.yaml
â”‚   â””â”€â”€ systemd/
â”‚       â”œâ”€â”€ amoskys-collector.service
â”‚       â””â”€â”€ amoskys-eventbus.service
â”‚
â”œâ”€â”€ ğŸ“š SHARED LIBRARIES/
â”‚   â”œâ”€â”€ src/amoskys/proto/                     # Generated protobuf code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ messaging_schema_pb2.py
â”‚   â”‚   â”œâ”€â”€ messaging_schema_pb2_grpc.py
â”‚   â”‚   â”œâ”€â”€ universal_telemetry_pb2.py
â”‚   â”‚   â””â”€â”€ universal_telemetry_pb2_grpc.py
â”‚   â”œâ”€â”€ src/amoskys/common/                    # Shared utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ crypto.py                          # Ed25519 signing
â”‚   â”‚   â”œâ”€â”€ logging_config.py                  # Logging setup
â”‚   â”‚   â”œâ”€â”€ metrics.py                         # Prometheus metrics
â”‚   â”‚   â””â”€â”€ config_loader.py                   # Configuration management
â”‚   â””â”€â”€ src/amoskys/utils/                     # Helper functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ time_utils.py
â”‚       â”œâ”€â”€ network_utils.py
â”‚       â””â”€â”€ file_utils.py
â”‚
â””â”€â”€ ğŸ“„ ROOT FILES/
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ .dockerignore
    â”œâ”€â”€ pyproject.toml                         # Python packaging
    â”œâ”€â”€ setup.py
    â”œâ”€â”€ requirements.txt                       # Core dependencies
    â”œâ”€â”€ requirements-dev.txt                   # Development dependencies
    â”œâ”€â”€ requirements-ml.txt                    # ML dependencies
    â”œâ”€â”€ LICENSE
    â””â”€â”€ Makefile                               # Build automation
```

---

## Migration Plan

### Phase 1: Documentation & Configuration (1 hour)

```bash
# Create new directory structure
mkdir -p DOCUMENTATION CONFIGURATION SCHEMAS/{proto,sql}

# Move documentation files
mv *.md DOCUMENTATION/

# Move configuration files
mv config.yaml snmp_config.yaml CONFIGURATION/

# Move schema files
cp -r proto SCHEMAS/
```

### Phase 2: Pipeline Stages (2-3 hours)

```bash
# Stage 1: Collection
mkdir -p "PIPELINE STAGE 1: DATA COLLECTION"/{src/amoskys/collectors,bin,tests}
mv src/amoskys/agents "PIPELINE STAGE 1: DATA COLLECTION"/src/amoskys/collectors
mv amoskys-snmp-agent "PIPELINE STAGE 1: DATA COLLECTION"/bin/amoskys-snmp-collector

# Stage 2: Ingestion
mkdir -p "PIPELINE STAGE 2: DATA INGESTION"/{src/amoskys/ingestion,bin,tests}
mv src/amoskys/eventbus "PIPELINE STAGE 2: DATA INGESTION"/src/amoskys/ingestion/
mv amoskys-eventbus "PIPELINE STAGE 2: DATA INGESTION"/bin/

# Stage 3: Transformation
mkdir -p "PIPELINE STAGE 3: DATA TRANSFORMATION"/src/amoskys/transformation/{extraction,processing,loading}
mkdir -p "PIPELINE STAGE 3: DATA TRANSFORMATION"/scripts/etl

# Stage 4: Intelligence
mkdir -p "PIPELINE STAGE 4: INTELLIGENCE"/{src/amoskys/intelligence,notebooks,scripts/ml}
mv notebooks "PIPELINE STAGE 4: INTELLIGENCE"/

# Stage 5: Presentation
mkdir -p "PIPELINE STAGE 5: PRESENTATION"/src/amoskys/presentation/{dashboard,cli,alerts}
mv src/amoskys/web "PIPELINE STAGE 5: PRESENTATION"/src/amoskys/presentation/dashboard
mv web "PIPELINE STAGE 5: PRESENTATION"/src/amoskys/presentation/dashboard/static
```

### Phase 3: Data & Tools (30 minutes)

```bash
# Data artifacts
mkdir -p DATA/{wal,features,models,checkpoints,exports}
mv data/wal DATA/
mv data/ml_pipeline DATA/features

# Analysis tools
mkdir -p "ANALYSIS TOOLS"/{scripts,tools}
mv scripts/inspect_wal_events.py "ANALYSIS TOOLS"/scripts/
mv scripts/visualize_timeline.py "ANALYSIS TOOLS"/scripts/
mv scripts/analyze_telemetry_pipeline.py "ANALYSIS TOOLS"/scripts/
```

### Phase 4: Testing & Deployment (1 hour)

```bash
# Testing
mkdir -p TESTING/tests/{unit,integration,performance,fixtures}
mv tests/* TESTING/tests/unit/

# Deployment
mkdir -p DEPLOYMENT/{docker,kubernetes,systemd}
```

### Phase 5: Update Import Paths (2 hours)

Update all Python imports to reflect new structure:

```python
# OLD:
from amoskys.agents.snmp.snmp_agent import SNMPAgent
from amoskys.eventbus.server import EventBusServicer

# NEW:
from amoskys.collectors.snmp.snmp_collector import SNMPCollector
from amoskys.ingestion.eventbus.server import EventBusServicer
```

**Automated approach:**

```bash
# Create a migration script
python scripts/update_imports.py --dry-run
python scripts/update_imports.py --apply
```

### Phase 6: Update Build & Config Files (1 hour)

Update:
- `setup.py` - Package entry points
- `Makefile` - Build targets
- `docker-compose.yml` - Volume mounts and paths
- `.gitignore` - New directory patterns
- CI/CD pipelines - Test & build paths

---

## Benefits of New Structure

### 1. **Data Flow Visibility**

```
Collection â†’ Ingestion â†’ Transformation â†’ Intelligence â†’ Presentation
   â†“            â†“             â†“              â†“              â†“
 Stage 1     Stage 2       Stage 3        Stage 4       Stage 5
```

Anyone can understand the pipeline by reading directory names.

### 2. **Separation of Concerns**

Each pipeline stage is self-contained:
- Independent testing
- Clear interfaces between stages
- Easy to swap implementations

### 3. **Developer Experience**

```bash
# Want to work on SNMP collection?
cd "PIPELINE STAGE 1: DATA COLLECTION"/src/amoskys/collectors/snmp

# Need to debug ETL?
cd "PIPELINE STAGE 3: DATA TRANSFORMATION"

# Deploy to production?
cd DEPLOYMENT/docker
```

### 4. **Onboarding**

New developers can:
1. Read `DOCUMENTATION/ARCHITECTURE.md` - Understand system design
2. Read `DOCUMENTATION/DATA_FLOW_ANALYSIS.md` - See actual data pipeline
3. Follow directory structure Stage 1 â†’ Stage 5 - Trace code execution
4. Run `scripts/quickstart.sh` - Get running in 5 minutes

### 5. **Scalability**

Easy to add new components:
- New collector? â†’ Add to Stage 1
- New ML model? â†’ Add to Stage 4
- New dashboard? â†’ Add to Stage 5

No confusion about where code belongs.

---

## Alternative: Simplified Structure (If Stage Names Too Verbose)

```
Amoskys/
â”œâ”€â”€ docs/                          # All documentation
â”œâ”€â”€ config/                        # All configuration
â”œâ”€â”€ schemas/                       # Protobuf & SQL schemas
â”‚
â”œâ”€â”€ collectors/                    # Stage 1: Data Collection
â”œâ”€â”€ ingestion/                     # Stage 2: EventBus + WAL
â”œâ”€â”€ transformation/                # Stage 3: ETL Pipeline
â”œâ”€â”€ intelligence/                  # Stage 4: ML Models
â”œâ”€â”€ presentation/                  # Stage 5: Dashboard & APIs
â”‚
â”œâ”€â”€ data/                          # All data artifacts
â”œâ”€â”€ tools/                         # Analysis & debugging tools
â”œâ”€â”€ tests/                         # All tests
â””â”€â”€ deployment/                    # Docker, K8s, etc.
```

This is cleaner while maintaining the same logical grouping.

---

## Recommendation

**Use the Simplified Structure** - It achieves the same goals without overly long directory names.

### Immediate Action

1. Create `tools/` directory and move analysis scripts:
   ```bash
   mkdir tools
   mv scripts/inspect_wal_events.py tools/
   mv scripts/visualize_timeline.py tools/
   mv scripts/analyze_telemetry_pipeline.py tools/
   ```

2. Rename `agents` to `collectors`:
   ```bash
   mv src/amoskys/agents src/amoskys/collectors
   mv amoskys-snmp-agent bin/amoskys-snmp-collector
   ```

3. Create `ingestion` directory:
   ```bash
   mkdir -p src/amoskys/ingestion
   mv src/amoskys/eventbus src/amoskys/ingestion/
   ```

4. Update imports (create migration script)

5. Update documentation to reflect new structure

### Full Migration Timeline

- **Phase 1 (Immediate)**: Move analysis tools to `tools/` - **5 minutes**
- **Phase 2 (Today)**: Rename agents â†’ collectors - **30 minutes**
- **Phase 3 (This Week)**: Full reorganization - **4-6 hours**
- **Phase 4 (Testing)**: Verify all imports work - **2 hours**
- **Phase 5 (Documentation)**: Update all docs - **1 hour**

**Total Effort**: 1 day of focused work

**Benefit**: Permanent improvement in code maintainability and developer onboarding

---

## Post-Migration Checklist

- [ ] All imports updated and working
- [ ] All tests passing
- [ ] Docker builds successfully
- [ ] Documentation reflects new structure
- [ ] CI/CD pipelines updated
- [ ] All executables work from new locations
- [ ] Git history preserved (use `git mv` not `mv`)
- [ ] Team notified of structure changes
- [ ] Migration guide shared with contributors

---

**Generated by**: Analysis of 1,403 real events and actual code structure
**Validated against**: Current repository state as of Oct 28, 2025
